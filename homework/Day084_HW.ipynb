{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Day084_HW.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9w-O4BkQpCQA"},"source":["## Work\n","### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"]},{"cell_type":"code","metadata":{"id":"ULoGKLUepCQI","executionInfo":{"status":"ok","timestamp":1613544059674,"user_tz":-480,"elapsed":2887,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["import os\n","import keras\n","import itertools\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ym0hcW-epCQJ","executionInfo":{"status":"ok","timestamp":1613545724068,"user_tz":-480,"elapsed":8847,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"9ad49c13-a495-4af8-a098-3714eb07e692"},"source":["train, test = keras.datasets.cifar10.load_data()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 6s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6cWSazE6pCQJ","executionInfo":{"status":"ok","timestamp":1613545724070,"user_tz":-480,"elapsed":8606,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["## 資料前處理\n","def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y    "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-sdTIY_pCQK","executionInfo":{"status":"ok","timestamp":1613545725593,"user_tz":-480,"elapsed":9924,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","# Preproc the inputs\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","# Preprc the outputs\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BDlR_T6kpCQK","executionInfo":{"status":"ok","timestamp":1613545725593,"user_tz":-480,"elapsed":4625,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["from keras.regularizers import l2\n","def build_mlp(input_dim, num_neurons = [512, 256, 128], l2_ratio = 1e-2, dropout_rate = 0.5):\n","    \"\"\"Code Here\n","    建立你的神經網路\n","    \"\"\"\n","    input_layer = keras.layers.Input(input_dim)\n","    for i, n_units in enumerate(num_neurons):\n","      if i == 0:\n","        hidden_layer = keras.layers.Dense(units=n_units, activation='relu', kernel_regularizer=l2(l2_ratio))(input_layer)\n","        hidden_layer = keras.layers.Dropout(dropout_rate)(hidden_layer)\n","        hidden_layer = keras.layers.BatchNormalization()(hidden_layer)\n","      else:\n","        hidden_layer = keras.layers.Dense(units=n_units, activation='relu', kernel_regularizer=l2(l2_ratio))(hidden_layer)\n","        hidden_layer = keras.layers.Dropout(dropout_rate)(hidden_layer)\n","        hidden_layer = keras.layers.BatchNormalization()(hidden_layer)\n","    output_layer = keras.layers.Dense(units=10, activation='softmax')(hidden_layer)\n","    model = keras.models.Model(inputs = [input_layer], outputs = [output_layer])\n","    return model"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Q6NeTegpCQK","executionInfo":{"status":"ok","timestamp":1613546580619,"user_tz":-480,"elapsed":1060,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["\"\"\"Code Here\n","設定超參數\n","\"\"\"\n","learning_rate = 1e-3\n","l2_set = [1e-2, 1e-3]\n","dropout_set = [0.2, 0.5]\n","batch_set = [64, 512]\n","epochs = 50\n","momentum = 0.9"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"foUXoHbIpCQK","executionInfo":{"status":"ok","timestamp":1613547428942,"user_tz":-480,"elapsed":846403,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"1979c328-2128-49a0-d575-23730ad00525"},"source":["results = {}\n","\"\"\"Code Here\n","撰寫你的訓練流程並將結果用 dictionary 紀錄\n","\"\"\"\n","for batch_size in batch_set:\n","  for l2_ratio in l2_set:\n","    for dropout_rate in dropout_set:\n","      keras.backend.clear_session()\n","      print('batch_size:{}, l2_ratio:{}, dropout_rate:{}'.format(batch_size, l2_ratio, dropout_rate))\n","      model = build_mlp(input_dim=x_train.shape[1:], l2_ratio=l2_ratio, dropout_rate=dropout_rate)\n","      adam = keras.optimizers.Adam(learning_rate=learning_rate)\n","      model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = adam)\n","      model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, validation_data = (x_test, y_test), shuffle = True)\n","\n","      train_loss = model.history.history['loss']\n","      val_loss = model.history.history['val_loss']\n","      train_acc = model.history.history['accuracy']\n","      val_acc = model.history.history['val_accuracy']\n","      name = 'batch_size:{}, l2_ratio:{}, dropout_rate:{}'.format(batch_size, l2_ratio, dropout_rate)\n","      results[name] = {'train_loss':train_loss, \n","                       'val_loss':val_loss, \n","                       'train_acc':train_acc, \n","                       'val_acc':val_acc}"],"execution_count":11,"outputs":[{"output_type":"stream","text":["batch_size:64, l2_ratio:0.01, dropout_rate:0.2\n","Epoch 1/50\n","782/782 [==============================] - 4s 5ms/step - loss: 7.6420 - accuracy: 0.2348 - val_loss: 2.5245 - val_accuracy: 0.2336\n","Epoch 2/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2403 - accuracy: 0.2820 - val_loss: 2.1885 - val_accuracy: 0.2401\n","Epoch 3/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0621 - accuracy: 0.2890 - val_loss: 2.0168 - val_accuracy: 0.2859\n","Epoch 4/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0331 - accuracy: 0.2831 - val_loss: 2.0114 - val_accuracy: 0.2803\n","Epoch 5/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0385 - accuracy: 0.2684 - val_loss: 2.7088 - val_accuracy: 0.1317\n","Epoch 6/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0116 - accuracy: 0.2842 - val_loss: 2.0727 - val_accuracy: 0.2358\n","Epoch 7/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0266 - accuracy: 0.2723 - val_loss: 2.3126 - val_accuracy: 0.1735\n","Epoch 8/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0143 - accuracy: 0.2793 - val_loss: 2.0557 - val_accuracy: 0.2595\n","Epoch 9/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0053 - accuracy: 0.2894 - val_loss: 1.9590 - val_accuracy: 0.3213\n","Epoch 10/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9942 - accuracy: 0.2935 - val_loss: 2.2906 - val_accuracy: 0.2252\n","Epoch 11/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0121 - accuracy: 0.2909 - val_loss: 2.0252 - val_accuracy: 0.2711\n","Epoch 12/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0032 - accuracy: 0.2884 - val_loss: 2.2066 - val_accuracy: 0.1966\n","Epoch 13/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0168 - accuracy: 0.2721 - val_loss: 2.0126 - val_accuracy: 0.2769\n","Epoch 14/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9933 - accuracy: 0.2888 - val_loss: 2.3110 - val_accuracy: 0.2115\n","Epoch 15/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0011 - accuracy: 0.2800 - val_loss: 2.2259 - val_accuracy: 0.1993\n","Epoch 16/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9980 - accuracy: 0.2811 - val_loss: 2.0853 - val_accuracy: 0.2627\n","Epoch 17/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9893 - accuracy: 0.2908 - val_loss: 2.1290 - val_accuracy: 0.2512\n","Epoch 18/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9843 - accuracy: 0.2864 - val_loss: 2.1956 - val_accuracy: 0.2226\n","Epoch 19/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9985 - accuracy: 0.2882 - val_loss: 2.0475 - val_accuracy: 0.2544\n","Epoch 20/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9841 - accuracy: 0.2912 - val_loss: 2.1381 - val_accuracy: 0.2297\n","Epoch 21/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9918 - accuracy: 0.2867 - val_loss: 1.9434 - val_accuracy: 0.3120\n","Epoch 22/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9767 - accuracy: 0.2944 - val_loss: 2.2335 - val_accuracy: 0.1897\n","Epoch 23/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0170 - accuracy: 0.2755 - val_loss: 2.1936 - val_accuracy: 0.2431\n","Epoch 24/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0061 - accuracy: 0.2740 - val_loss: 2.1247 - val_accuracy: 0.2326\n","Epoch 25/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9967 - accuracy: 0.2851 - val_loss: 2.0605 - val_accuracy: 0.2559\n","Epoch 26/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0023 - accuracy: 0.2798 - val_loss: 2.1242 - val_accuracy: 0.2534\n","Epoch 27/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.9916 - accuracy: 0.2884 - val_loss: 2.1589 - val_accuracy: 0.2152\n","Epoch 28/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.9854 - accuracy: 0.2915 - val_loss: 2.1379 - val_accuracy: 0.2184\n","Epoch 29/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.9904 - accuracy: 0.2833 - val_loss: 2.2863 - val_accuracy: 0.2248\n","Epoch 30/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9922 - accuracy: 0.2857 - val_loss: 2.0327 - val_accuracy: 0.2944\n","Epoch 31/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9980 - accuracy: 0.2780 - val_loss: 2.1464 - val_accuracy: 0.2181\n","Epoch 32/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9849 - accuracy: 0.2856 - val_loss: 2.0246 - val_accuracy: 0.2710\n","Epoch 33/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0144 - accuracy: 0.2692 - val_loss: 2.1768 - val_accuracy: 0.2161\n","Epoch 34/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0001 - accuracy: 0.2741 - val_loss: 2.0920 - val_accuracy: 0.2164\n","Epoch 35/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9997 - accuracy: 0.2751 - val_loss: 2.1365 - val_accuracy: 0.2429\n","Epoch 36/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0022 - accuracy: 0.2763 - val_loss: 2.1936 - val_accuracy: 0.2055\n","Epoch 37/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9946 - accuracy: 0.2734 - val_loss: 2.1187 - val_accuracy: 0.2547\n","Epoch 38/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9904 - accuracy: 0.2823 - val_loss: 2.0755 - val_accuracy: 0.2559\n","Epoch 39/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9834 - accuracy: 0.2893 - val_loss: 2.2337 - val_accuracy: 0.2261\n","Epoch 40/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9817 - accuracy: 0.2919 - val_loss: 2.1610 - val_accuracy: 0.2248\n","Epoch 41/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9722 - accuracy: 0.2910 - val_loss: 1.9383 - val_accuracy: 0.3278\n","Epoch 42/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9686 - accuracy: 0.2960 - val_loss: 2.0019 - val_accuracy: 0.2881\n","Epoch 43/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9754 - accuracy: 0.2970 - val_loss: 1.9276 - val_accuracy: 0.3163\n","Epoch 44/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9756 - accuracy: 0.2916 - val_loss: 2.0996 - val_accuracy: 0.2594\n","Epoch 45/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9718 - accuracy: 0.2932 - val_loss: 2.1770 - val_accuracy: 0.2278\n","Epoch 46/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9738 - accuracy: 0.2919 - val_loss: 2.1473 - val_accuracy: 0.2227\n","Epoch 47/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9850 - accuracy: 0.2879 - val_loss: 2.0269 - val_accuracy: 0.2900\n","Epoch 48/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9799 - accuracy: 0.2872 - val_loss: 1.9761 - val_accuracy: 0.3158\n","Epoch 49/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9781 - accuracy: 0.2928 - val_loss: 2.1706 - val_accuracy: 0.2409\n","Epoch 50/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9790 - accuracy: 0.2943 - val_loss: 2.1454 - val_accuracy: 0.2607\n","batch_size:64, l2_ratio:0.01, dropout_rate:0.5\n","Epoch 1/50\n","782/782 [==============================] - 4s 5ms/step - loss: 7.7630 - accuracy: 0.1532 - val_loss: 2.5689 - val_accuracy: 0.1965\n","Epoch 2/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.4808 - accuracy: 0.1851 - val_loss: 2.5908 - val_accuracy: 0.1033\n","Epoch 3/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2643 - accuracy: 0.1849 - val_loss: 2.2148 - val_accuracy: 0.2017\n","Epoch 4/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2225 - accuracy: 0.1888 - val_loss: 2.2310 - val_accuracy: 0.2064\n","Epoch 5/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2187 - accuracy: 0.1756 - val_loss: 2.2879 - val_accuracy: 0.1561\n","Epoch 6/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1922 - accuracy: 0.1810 - val_loss: 2.3990 - val_accuracy: 0.1201\n","Epoch 7/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2130 - accuracy: 0.1785 - val_loss: 2.3671 - val_accuracy: 0.1154\n","Epoch 8/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2130 - accuracy: 0.1688 - val_loss: 2.1949 - val_accuracy: 0.2099\n","Epoch 9/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1952 - accuracy: 0.1793 - val_loss: 2.1731 - val_accuracy: 0.2043\n","Epoch 10/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2227 - accuracy: 0.1655 - val_loss: 2.2134 - val_accuracy: 0.1525\n","Epoch 11/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2056 - accuracy: 0.1784 - val_loss: 2.2232 - val_accuracy: 0.1747\n","Epoch 12/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1658 - accuracy: 0.1868 - val_loss: 2.4291 - val_accuracy: 0.1106\n","Epoch 13/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1946 - accuracy: 0.1744 - val_loss: 2.2874 - val_accuracy: 0.1399\n","Epoch 14/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2110 - accuracy: 0.1643 - val_loss: 2.2121 - val_accuracy: 0.1538\n","Epoch 15/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1820 - accuracy: 0.1766 - val_loss: 2.3358 - val_accuracy: 0.1240\n","Epoch 16/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1993 - accuracy: 0.1721 - val_loss: 2.2653 - val_accuracy: 0.1377\n","Epoch 17/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2119 - accuracy: 0.1569 - val_loss: 2.2174 - val_accuracy: 0.1505\n","Epoch 18/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1860 - accuracy: 0.1782 - val_loss: 2.3614 - val_accuracy: 0.1159\n","Epoch 19/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1953 - accuracy: 0.1778 - val_loss: 2.2380 - val_accuracy: 0.2050\n","Epoch 20/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1783 - accuracy: 0.1800 - val_loss: 2.3054 - val_accuracy: 0.1182\n","Epoch 21/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2034 - accuracy: 0.1659 - val_loss: 2.3217 - val_accuracy: 0.1274\n","Epoch 22/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2078 - accuracy: 0.1632 - val_loss: 2.1800 - val_accuracy: 0.1944\n","Epoch 23/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2066 - accuracy: 0.1686 - val_loss: 2.2897 - val_accuracy: 0.1304\n","Epoch 24/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2188 - accuracy: 0.1596 - val_loss: 2.2778 - val_accuracy: 0.1294\n","Epoch 25/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2637 - accuracy: 0.1351 - val_loss: 2.2180 - val_accuracy: 0.1639\n","Epoch 26/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2229 - accuracy: 0.1561 - val_loss: 2.2905 - val_accuracy: 0.1587\n","Epoch 27/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2226 - accuracy: 0.1565 - val_loss: 2.2581 - val_accuracy: 0.1492\n","Epoch 28/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2278 - accuracy: 0.1607 - val_loss: 2.3349 - val_accuracy: 0.1046\n","Epoch 29/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2066 - accuracy: 0.1640 - val_loss: 2.3304 - val_accuracy: 0.1037\n","Epoch 30/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2045 - accuracy: 0.1603 - val_loss: 2.3146 - val_accuracy: 0.1019\n","Epoch 31/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2233 - accuracy: 0.1629 - val_loss: 2.3124 - val_accuracy: 0.1134\n","Epoch 32/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2230 - accuracy: 0.1592 - val_loss: 2.3806 - val_accuracy: 0.1005\n","Epoch 33/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2311 - accuracy: 0.1528 - val_loss: 2.3522 - val_accuracy: 0.1010\n","Epoch 34/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2234 - accuracy: 0.1519 - val_loss: 2.3468 - val_accuracy: 0.1088\n","Epoch 35/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2254 - accuracy: 0.1542 - val_loss: 2.2551 - val_accuracy: 0.1718\n","Epoch 36/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2133 - accuracy: 0.1638 - val_loss: 2.3837 - val_accuracy: 0.1006\n","Epoch 37/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2291 - accuracy: 0.1552 - val_loss: 2.2101 - val_accuracy: 0.1757\n","Epoch 38/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2251 - accuracy: 0.1604 - val_loss: 2.2255 - val_accuracy: 0.1343\n","Epoch 39/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2647 - accuracy: 0.1386 - val_loss: 2.2874 - val_accuracy: 0.1255\n","Epoch 40/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2362 - accuracy: 0.1494 - val_loss: 2.3139 - val_accuracy: 0.1059\n","Epoch 41/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2429 - accuracy: 0.1442 - val_loss: 2.3292 - val_accuracy: 0.1057\n","Epoch 42/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2157 - accuracy: 0.1563 - val_loss: 2.3810 - val_accuracy: 0.1003\n","Epoch 43/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2640 - accuracy: 0.1378 - val_loss: 2.2762 - val_accuracy: 0.1314\n","Epoch 44/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2427 - accuracy: 0.1415 - val_loss: 2.2811 - val_accuracy: 0.1210\n","Epoch 45/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2233 - accuracy: 0.1574 - val_loss: 2.3536 - val_accuracy: 0.1010\n","Epoch 46/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2463 - accuracy: 0.1394 - val_loss: 2.3281 - val_accuracy: 0.1011\n","Epoch 47/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2456 - accuracy: 0.1413 - val_loss: 2.3440 - val_accuracy: 0.1035\n","Epoch 48/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2625 - accuracy: 0.1318 - val_loss: 2.3476 - val_accuracy: 0.1024\n","Epoch 49/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2207 - accuracy: 0.1552 - val_loss: 2.2992 - val_accuracy: 0.1159\n","Epoch 50/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2579 - accuracy: 0.1345 - val_loss: 2.2996 - val_accuracy: 0.1157\n","batch_size:64, l2_ratio:0.001, dropout_rate:0.2\n","Epoch 1/50\n","782/782 [==============================] - 5s 5ms/step - loss: 3.2702 - accuracy: 0.2477 - val_loss: 2.4720 - val_accuracy: 0.2625\n","Epoch 2/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.3239 - accuracy: 0.3079 - val_loss: 2.2768 - val_accuracy: 0.2680\n","Epoch 3/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0800 - accuracy: 0.3222 - val_loss: 2.0076 - val_accuracy: 0.3094\n","Epoch 4/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9609 - accuracy: 0.3399 - val_loss: 2.0087 - val_accuracy: 0.2908\n","Epoch 5/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8941 - accuracy: 0.3539 - val_loss: 1.8731 - val_accuracy: 0.3425\n","Epoch 6/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.9030 - accuracy: 0.3439 - val_loss: 2.0501 - val_accuracy: 0.2978\n","Epoch 7/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8560 - accuracy: 0.3596 - val_loss: 1.8581 - val_accuracy: 0.3615\n","Epoch 8/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8815 - accuracy: 0.3482 - val_loss: 1.8046 - val_accuracy: 0.3797\n","Epoch 9/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8536 - accuracy: 0.3600 - val_loss: 2.0603 - val_accuracy: 0.2895\n","Epoch 10/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8372 - accuracy: 0.3697 - val_loss: 1.9365 - val_accuracy: 0.3081\n","Epoch 11/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8361 - accuracy: 0.3592 - val_loss: 2.1889 - val_accuracy: 0.2652\n","Epoch 12/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8413 - accuracy: 0.3629 - val_loss: 1.8706 - val_accuracy: 0.3545\n","Epoch 13/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8446 - accuracy: 0.3649 - val_loss: 1.8378 - val_accuracy: 0.3626\n","Epoch 14/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8314 - accuracy: 0.3665 - val_loss: 1.9064 - val_accuracy: 0.3316\n","Epoch 15/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8299 - accuracy: 0.3655 - val_loss: 1.7993 - val_accuracy: 0.3836\n","Epoch 16/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8362 - accuracy: 0.3657 - val_loss: 1.9948 - val_accuracy: 0.2970\n","Epoch 17/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8237 - accuracy: 0.3651 - val_loss: 1.8007 - val_accuracy: 0.3769\n","Epoch 18/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.8390 - accuracy: 0.3690 - val_loss: 1.7868 - val_accuracy: 0.3758\n","Epoch 19/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.8507 - accuracy: 0.3564 - val_loss: 1.8884 - val_accuracy: 0.3418\n","Epoch 20/50\n","782/782 [==============================] - 4s 5ms/step - loss: 1.8399 - accuracy: 0.3607 - val_loss: 1.8470 - val_accuracy: 0.3498\n","Epoch 21/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8569 - accuracy: 0.3516 - val_loss: 1.8557 - val_accuracy: 0.3536\n","Epoch 22/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8475 - accuracy: 0.3575 - val_loss: 1.9188 - val_accuracy: 0.3226\n","Epoch 23/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8662 - accuracy: 0.3494 - val_loss: 1.8622 - val_accuracy: 0.3434\n","Epoch 24/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8864 - accuracy: 0.3384 - val_loss: 1.8670 - val_accuracy: 0.3275\n","Epoch 25/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8561 - accuracy: 0.3544 - val_loss: 1.8071 - val_accuracy: 0.3664\n","Epoch 26/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8311 - accuracy: 0.3620 - val_loss: 1.8258 - val_accuracy: 0.3641\n","Epoch 27/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8313 - accuracy: 0.3668 - val_loss: 1.8488 - val_accuracy: 0.3501\n","Epoch 28/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8279 - accuracy: 0.3661 - val_loss: 1.8319 - val_accuracy: 0.3636\n","Epoch 29/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8271 - accuracy: 0.3673 - val_loss: 1.7670 - val_accuracy: 0.3937\n","Epoch 30/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8194 - accuracy: 0.3661 - val_loss: 1.9304 - val_accuracy: 0.3263\n","Epoch 31/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8309 - accuracy: 0.3665 - val_loss: 1.9492 - val_accuracy: 0.3143\n","Epoch 32/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8517 - accuracy: 0.3547 - val_loss: 1.9297 - val_accuracy: 0.3490\n","Epoch 33/50\n","782/782 [==============================] - 4s 4ms/step - loss: 1.8361 - accuracy: 0.3611 - val_loss: 1.9295 - val_accuracy: 0.3164\n","Epoch 34/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8275 - accuracy: 0.3668 - val_loss: 1.8213 - val_accuracy: 0.3636\n","Epoch 35/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8266 - accuracy: 0.3595 - val_loss: 1.8231 - val_accuracy: 0.3664\n","Epoch 36/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8280 - accuracy: 0.3665 - val_loss: 1.8156 - val_accuracy: 0.3663\n","Epoch 37/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8348 - accuracy: 0.3651 - val_loss: 1.7961 - val_accuracy: 0.3711\n","Epoch 38/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8193 - accuracy: 0.3687 - val_loss: 1.7884 - val_accuracy: 0.3797\n","Epoch 39/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8266 - accuracy: 0.3658 - val_loss: 1.8608 - val_accuracy: 0.3487\n","Epoch 40/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8273 - accuracy: 0.3655 - val_loss: 1.8767 - val_accuracy: 0.3183\n","Epoch 41/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8368 - accuracy: 0.3629 - val_loss: 1.9037 - val_accuracy: 0.3282\n","Epoch 42/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8383 - accuracy: 0.3607 - val_loss: 2.0478 - val_accuracy: 0.2881\n","Epoch 43/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8278 - accuracy: 0.3596 - val_loss: 1.9173 - val_accuracy: 0.3359\n","Epoch 44/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8294 - accuracy: 0.3610 - val_loss: 1.9552 - val_accuracy: 0.3247\n","Epoch 45/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8361 - accuracy: 0.3577 - val_loss: 1.8071 - val_accuracy: 0.3740\n","Epoch 46/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8237 - accuracy: 0.3625 - val_loss: 1.9578 - val_accuracy: 0.3233\n","Epoch 47/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8311 - accuracy: 0.3628 - val_loss: 1.8796 - val_accuracy: 0.3440\n","Epoch 48/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8280 - accuracy: 0.3626 - val_loss: 1.9418 - val_accuracy: 0.3247\n","Epoch 49/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8339 - accuracy: 0.3591 - val_loss: 2.0067 - val_accuracy: 0.2956\n","Epoch 50/50\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8266 - accuracy: 0.3635 - val_loss: 1.9911 - val_accuracy: 0.3236\n","batch_size:64, l2_ratio:0.001, dropout_rate:0.5\n","Epoch 1/50\n","782/782 [==============================] - 5s 5ms/step - loss: 3.4882 - accuracy: 0.1686 - val_loss: 2.7202 - val_accuracy: 0.1384\n","Epoch 2/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.4508 - accuracy: 0.2336 - val_loss: 2.2765 - val_accuracy: 0.2452\n","Epoch 3/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.2502 - accuracy: 0.2338 - val_loss: 2.1435 - val_accuracy: 0.2610\n","Epoch 4/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1652 - accuracy: 0.2306 - val_loss: 2.3462 - val_accuracy: 0.1440\n","Epoch 5/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1300 - accuracy: 0.2320 - val_loss: 2.1622 - val_accuracy: 0.2141\n","Epoch 6/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1097 - accuracy: 0.2267 - val_loss: 2.1676 - val_accuracy: 0.2193\n","Epoch 7/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0951 - accuracy: 0.2356 - val_loss: 2.3151 - val_accuracy: 0.1589\n","Epoch 8/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1233 - accuracy: 0.2095 - val_loss: 2.1458 - val_accuracy: 0.1732\n","Epoch 9/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0962 - accuracy: 0.2147 - val_loss: 2.2599 - val_accuracy: 0.1604\n","Epoch 10/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1213 - accuracy: 0.2097 - val_loss: 2.1708 - val_accuracy: 0.1984\n","Epoch 11/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1424 - accuracy: 0.1961 - val_loss: 2.3077 - val_accuracy: 0.1284\n","Epoch 12/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1422 - accuracy: 0.1868 - val_loss: 2.1922 - val_accuracy: 0.1657\n","Epoch 13/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1436 - accuracy: 0.1868 - val_loss: 2.1768 - val_accuracy: 0.1783\n","Epoch 14/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1187 - accuracy: 0.2014 - val_loss: 2.1952 - val_accuracy: 0.1705\n","Epoch 15/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1211 - accuracy: 0.2028 - val_loss: 2.1788 - val_accuracy: 0.1856\n","Epoch 16/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1211 - accuracy: 0.1995 - val_loss: 2.1381 - val_accuracy: 0.1805\n","Epoch 17/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1215 - accuracy: 0.1940 - val_loss: 2.1766 - val_accuracy: 0.1737\n","Epoch 18/50\n","782/782 [==============================] - 4s 5ms/step - loss: 2.1132 - accuracy: 0.1923 - val_loss: 2.1468 - val_accuracy: 0.2078\n","Epoch 19/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1001 - accuracy: 0.2075 - val_loss: 2.1981 - val_accuracy: 0.1744\n","Epoch 20/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0959 - accuracy: 0.2072 - val_loss: 2.1930 - val_accuracy: 0.2009\n","Epoch 21/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1409 - accuracy: 0.1903 - val_loss: 2.1694 - val_accuracy: 0.1811\n","Epoch 22/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1452 - accuracy: 0.1864 - val_loss: 2.2431 - val_accuracy: 0.1570\n","Epoch 23/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1351 - accuracy: 0.1865 - val_loss: 2.2492 - val_accuracy: 0.1673\n","Epoch 24/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1441 - accuracy: 0.1815 - val_loss: 2.3399 - val_accuracy: 0.1390\n","Epoch 25/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1201 - accuracy: 0.1918 - val_loss: 2.1595 - val_accuracy: 0.1689\n","Epoch 26/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0870 - accuracy: 0.2133 - val_loss: 2.3012 - val_accuracy: 0.1305\n","Epoch 27/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1197 - accuracy: 0.2011 - val_loss: 2.2601 - val_accuracy: 0.1526\n","Epoch 28/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0978 - accuracy: 0.2038 - val_loss: 2.1500 - val_accuracy: 0.1851\n","Epoch 29/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1100 - accuracy: 0.1981 - val_loss: 2.2167 - val_accuracy: 0.1515\n","Epoch 30/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1002 - accuracy: 0.2048 - val_loss: 2.1625 - val_accuracy: 0.1853\n","Epoch 31/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0894 - accuracy: 0.2046 - val_loss: 2.1358 - val_accuracy: 0.1829\n","Epoch 32/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0988 - accuracy: 0.2030 - val_loss: 2.2872 - val_accuracy: 0.1460\n","Epoch 33/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1222 - accuracy: 0.2024 - val_loss: 2.2418 - val_accuracy: 0.1583\n","Epoch 34/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1031 - accuracy: 0.2102 - val_loss: 2.1769 - val_accuracy: 0.1781\n","Epoch 35/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1132 - accuracy: 0.1980 - val_loss: 2.1834 - val_accuracy: 0.1906\n","Epoch 36/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0972 - accuracy: 0.2057 - val_loss: 2.1881 - val_accuracy: 0.1855\n","Epoch 37/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1004 - accuracy: 0.2056 - val_loss: 2.1698 - val_accuracy: 0.1947\n","Epoch 38/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0815 - accuracy: 0.2130 - val_loss: 2.2753 - val_accuracy: 0.1469\n","Epoch 39/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.0862 - accuracy: 0.2160 - val_loss: 2.1653 - val_accuracy: 0.1703\n","Epoch 40/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1111 - accuracy: 0.2048 - val_loss: 2.2470 - val_accuracy: 0.1641\n","Epoch 41/50\n","782/782 [==============================] - 4s 5ms/step - loss: 2.0970 - accuracy: 0.2087 - val_loss: 2.2714 - val_accuracy: 0.1323\n","Epoch 42/50\n","782/782 [==============================] - 4s 4ms/step - loss: 2.0977 - accuracy: 0.2105 - val_loss: 2.2126 - val_accuracy: 0.1604\n","Epoch 43/50\n","782/782 [==============================] - 4s 5ms/step - loss: 2.0862 - accuracy: 0.2074 - val_loss: 2.1482 - val_accuracy: 0.1832\n","Epoch 44/50\n","782/782 [==============================] - 4s 5ms/step - loss: 2.1083 - accuracy: 0.2024 - val_loss: 2.2327 - val_accuracy: 0.1501\n","Epoch 45/50\n","782/782 [==============================] - 4s 4ms/step - loss: 2.1221 - accuracy: 0.1967 - val_loss: 2.2511 - val_accuracy: 0.1571\n","Epoch 46/50\n","782/782 [==============================] - 4s 4ms/step - loss: 2.1199 - accuracy: 0.1974 - val_loss: 2.2484 - val_accuracy: 0.1544\n","Epoch 47/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1018 - accuracy: 0.1977 - val_loss: 2.1194 - val_accuracy: 0.1987\n","Epoch 48/50\n","782/782 [==============================] - 4s 5ms/step - loss: 2.0863 - accuracy: 0.2133 - val_loss: 2.1951 - val_accuracy: 0.1770\n","Epoch 49/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1208 - accuracy: 0.2009 - val_loss: 2.2102 - val_accuracy: 0.1808\n","Epoch 50/50\n","782/782 [==============================] - 3s 4ms/step - loss: 2.1214 - accuracy: 0.1941 - val_loss: 2.1890 - val_accuracy: 0.1703\n","batch_size:512, l2_ratio:0.01, dropout_rate:0.2\n","Epoch 1/50\n","98/98 [==============================] - 2s 10ms/step - loss: 12.0329 - accuracy: 0.2382 - val_loss: 4.3913 - val_accuracy: 0.2841\n","Epoch 2/50\n","98/98 [==============================] - 1s 8ms/step - loss: 3.6684 - accuracy: 0.3275 - val_loss: 2.9920 - val_accuracy: 0.1720\n","Epoch 3/50\n","98/98 [==============================] - 1s 7ms/step - loss: 2.4756 - accuracy: 0.3483 - val_loss: 2.7143 - val_accuracy: 0.1472\n","Epoch 4/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.1551 - accuracy: 0.3548 - val_loss: 2.3191 - val_accuracy: 0.2267\n","Epoch 5/50\n","98/98 [==============================] - 1s 7ms/step - loss: 2.0093 - accuracy: 0.3646 - val_loss: 2.1011 - val_accuracy: 0.3036\n","Epoch 6/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9448 - accuracy: 0.3658 - val_loss: 2.0247 - val_accuracy: 0.3489\n","Epoch 7/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8757 - accuracy: 0.3794 - val_loss: 1.9718 - val_accuracy: 0.3367\n","Epoch 8/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.8620 - accuracy: 0.3794 - val_loss: 1.9012 - val_accuracy: 0.3533\n","Epoch 9/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.8403 - accuracy: 0.3813 - val_loss: 1.8490 - val_accuracy: 0.3720\n","Epoch 10/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8207 - accuracy: 0.3856 - val_loss: 2.0431 - val_accuracy: 0.3115\n","Epoch 11/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8201 - accuracy: 0.3861 - val_loss: 1.8412 - val_accuracy: 0.3896\n","Epoch 12/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7934 - accuracy: 0.3917 - val_loss: 1.8595 - val_accuracy: 0.3702\n","Epoch 13/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7892 - accuracy: 0.3959 - val_loss: 2.0681 - val_accuracy: 0.2810\n","Epoch 14/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.8030 - accuracy: 0.3952 - val_loss: 1.8380 - val_accuracy: 0.3713\n","Epoch 15/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7959 - accuracy: 0.3971 - val_loss: 1.8479 - val_accuracy: 0.3637\n","Epoch 16/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7777 - accuracy: 0.3997 - val_loss: 1.7704 - val_accuracy: 0.4055\n","Epoch 17/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.7729 - accuracy: 0.4043 - val_loss: 1.8275 - val_accuracy: 0.3814\n","Epoch 18/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7808 - accuracy: 0.3999 - val_loss: 1.8809 - val_accuracy: 0.3611\n","Epoch 19/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7642 - accuracy: 0.4052 - val_loss: 1.8694 - val_accuracy: 0.3618\n","Epoch 20/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7700 - accuracy: 0.4010 - val_loss: 1.8958 - val_accuracy: 0.3475\n","Epoch 21/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7668 - accuracy: 0.4030 - val_loss: 1.7942 - val_accuracy: 0.3875\n","Epoch 22/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7626 - accuracy: 0.4026 - val_loss: 1.8326 - val_accuracy: 0.3826\n","Epoch 23/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7604 - accuracy: 0.4072 - val_loss: 1.8503 - val_accuracy: 0.3681\n","Epoch 24/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7732 - accuracy: 0.4053 - val_loss: 1.8340 - val_accuracy: 0.3738\n","Epoch 25/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.7557 - accuracy: 0.4055 - val_loss: 1.8832 - val_accuracy: 0.3620\n","Epoch 26/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.7676 - accuracy: 0.4005 - val_loss: 1.9588 - val_accuracy: 0.3354\n","Epoch 27/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7574 - accuracy: 0.4042 - val_loss: 1.8156 - val_accuracy: 0.3814\n","Epoch 28/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.7549 - accuracy: 0.4044 - val_loss: 2.1649 - val_accuracy: 0.3004\n","Epoch 29/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7549 - accuracy: 0.4037 - val_loss: 1.8092 - val_accuracy: 0.3845\n","Epoch 30/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7442 - accuracy: 0.4091 - val_loss: 1.8601 - val_accuracy: 0.3673\n","Epoch 31/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7472 - accuracy: 0.4113 - val_loss: 1.8078 - val_accuracy: 0.3896\n","Epoch 32/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7531 - accuracy: 0.4100 - val_loss: 1.8781 - val_accuracy: 0.3547\n","Epoch 33/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7485 - accuracy: 0.4079 - val_loss: 1.8372 - val_accuracy: 0.3745\n","Epoch 34/50\n","98/98 [==============================] - 1s 9ms/step - loss: 1.7450 - accuracy: 0.4095 - val_loss: 1.8402 - val_accuracy: 0.3796\n","Epoch 35/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7518 - accuracy: 0.4060 - val_loss: 1.8131 - val_accuracy: 0.3776\n","Epoch 36/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7399 - accuracy: 0.4083 - val_loss: 2.3169 - val_accuracy: 0.2376\n","Epoch 37/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7738 - accuracy: 0.3975 - val_loss: 1.9744 - val_accuracy: 0.3227\n","Epoch 38/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7459 - accuracy: 0.4050 - val_loss: 1.8592 - val_accuracy: 0.3703\n","Epoch 39/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7521 - accuracy: 0.4065 - val_loss: 1.8627 - val_accuracy: 0.3683\n","Epoch 40/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7452 - accuracy: 0.4047 - val_loss: 1.8761 - val_accuracy: 0.3587\n","Epoch 41/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7633 - accuracy: 0.3987 - val_loss: 1.8295 - val_accuracy: 0.3679\n","Epoch 42/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7477 - accuracy: 0.4060 - val_loss: 1.8884 - val_accuracy: 0.3569\n","Epoch 43/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7471 - accuracy: 0.4014 - val_loss: 1.8941 - val_accuracy: 0.3576\n","Epoch 44/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7461 - accuracy: 0.4040 - val_loss: 1.9480 - val_accuracy: 0.3389\n","Epoch 45/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7480 - accuracy: 0.4057 - val_loss: 1.8381 - val_accuracy: 0.3804\n","Epoch 46/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7408 - accuracy: 0.4052 - val_loss: 1.8998 - val_accuracy: 0.3496\n","Epoch 47/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7430 - accuracy: 0.4080 - val_loss: 1.8243 - val_accuracy: 0.3782\n","Epoch 48/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7382 - accuracy: 0.4091 - val_loss: 1.8072 - val_accuracy: 0.3973\n","Epoch 49/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7425 - accuracy: 0.4040 - val_loss: 1.9257 - val_accuracy: 0.3444\n","Epoch 50/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7295 - accuracy: 0.4139 - val_loss: 1.9520 - val_accuracy: 0.3293\n","batch_size:512, l2_ratio:0.01, dropout_rate:0.5\n","Epoch 1/50\n","98/98 [==============================] - 2s 10ms/step - loss: 11.9337 - accuracy: 0.1569 - val_loss: 4.3020 - val_accuracy: 0.2772\n","Epoch 2/50\n","98/98 [==============================] - 1s 8ms/step - loss: 3.8321 - accuracy: 0.2295 - val_loss: 2.9733 - val_accuracy: 0.1605\n","Epoch 3/50\n","98/98 [==============================] - 1s 7ms/step - loss: 2.6549 - accuracy: 0.2599 - val_loss: 2.5436 - val_accuracy: 0.1969\n","Epoch 4/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.2981 - accuracy: 0.2795 - val_loss: 2.3326 - val_accuracy: 0.2641\n","Epoch 5/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.2315 - accuracy: 0.2693 - val_loss: 2.3994 - val_accuracy: 0.1975\n","Epoch 6/50\n","98/98 [==============================] - 1s 7ms/step - loss: 2.1460 - accuracy: 0.2716 - val_loss: 2.2849 - val_accuracy: 0.2168\n","Epoch 7/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.1018 - accuracy: 0.2776 - val_loss: 2.1256 - val_accuracy: 0.2499\n","Epoch 8/50\n","98/98 [==============================] - 1s 7ms/step - loss: 2.0765 - accuracy: 0.2753 - val_loss: 2.0980 - val_accuracy: 0.2937\n","Epoch 9/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0601 - accuracy: 0.2828 - val_loss: 2.0741 - val_accuracy: 0.2613\n","Epoch 10/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0563 - accuracy: 0.2797 - val_loss: 2.1619 - val_accuracy: 0.2502\n","Epoch 11/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0510 - accuracy: 0.2757 - val_loss: 2.1278 - val_accuracy: 0.2766\n","Epoch 12/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0613 - accuracy: 0.2636 - val_loss: 2.0992 - val_accuracy: 0.2561\n","Epoch 13/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0328 - accuracy: 0.2703 - val_loss: 2.0623 - val_accuracy: 0.2465\n","Epoch 14/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0365 - accuracy: 0.2738 - val_loss: 2.2605 - val_accuracy: 0.1722\n","Epoch 15/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0239 - accuracy: 0.2751 - val_loss: 2.1355 - val_accuracy: 0.2703\n","Epoch 16/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0204 - accuracy: 0.2745 - val_loss: 2.2759 - val_accuracy: 0.2064\n","Epoch 17/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0132 - accuracy: 0.2793 - val_loss: 2.2292 - val_accuracy: 0.1839\n","Epoch 18/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0144 - accuracy: 0.2818 - val_loss: 2.2546 - val_accuracy: 0.2106\n","Epoch 19/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0093 - accuracy: 0.2853 - val_loss: 2.1321 - val_accuracy: 0.2283\n","Epoch 20/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0127 - accuracy: 0.2766 - val_loss: 2.2514 - val_accuracy: 0.2027\n","Epoch 21/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9966 - accuracy: 0.2895 - val_loss: 2.1357 - val_accuracy: 0.2286\n","Epoch 22/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0071 - accuracy: 0.2843 - val_loss: 2.1201 - val_accuracy: 0.2228\n","Epoch 23/50\n","98/98 [==============================] - 1s 9ms/step - loss: 2.0029 - accuracy: 0.2904 - val_loss: 2.1122 - val_accuracy: 0.2386\n","Epoch 24/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0041 - accuracy: 0.2860 - val_loss: 2.1240 - val_accuracy: 0.2096\n","Epoch 25/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0004 - accuracy: 0.2852 - val_loss: 2.1776 - val_accuracy: 0.2207\n","Epoch 26/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0035 - accuracy: 0.2854 - val_loss: 2.2227 - val_accuracy: 0.2284\n","Epoch 27/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9899 - accuracy: 0.2898 - val_loss: 2.1664 - val_accuracy: 0.2412\n","Epoch 28/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9945 - accuracy: 0.2844 - val_loss: 2.1637 - val_accuracy: 0.2483\n","Epoch 29/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9901 - accuracy: 0.2894 - val_loss: 2.2128 - val_accuracy: 0.1992\n","Epoch 30/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9951 - accuracy: 0.2845 - val_loss: 2.2380 - val_accuracy: 0.2254\n","Epoch 31/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9991 - accuracy: 0.2872 - val_loss: 2.1428 - val_accuracy: 0.2429\n","Epoch 32/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0043 - accuracy: 0.2837 - val_loss: 2.2934 - val_accuracy: 0.1929\n","Epoch 33/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0009 - accuracy: 0.2828 - val_loss: 2.2099 - val_accuracy: 0.1958\n","Epoch 34/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9965 - accuracy: 0.2870 - val_loss: 2.2056 - val_accuracy: 0.2194\n","Epoch 35/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0042 - accuracy: 0.2863 - val_loss: 2.1706 - val_accuracy: 0.2224\n","Epoch 36/50\n","98/98 [==============================] - 1s 9ms/step - loss: 1.9861 - accuracy: 0.2918 - val_loss: 2.2497 - val_accuracy: 0.1847\n","Epoch 37/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0043 - accuracy: 0.2894 - val_loss: 2.1063 - val_accuracy: 0.2389\n","Epoch 38/50\n","98/98 [==============================] - 1s 9ms/step - loss: 2.0047 - accuracy: 0.2797 - val_loss: 2.1564 - val_accuracy: 0.2339\n","Epoch 39/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9882 - accuracy: 0.2900 - val_loss: 2.3212 - val_accuracy: 0.1512\n","Epoch 40/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9933 - accuracy: 0.2842 - val_loss: 2.3469 - val_accuracy: 0.1627\n","Epoch 41/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9934 - accuracy: 0.2913 - val_loss: 2.2727 - val_accuracy: 0.1860\n","Epoch 42/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0083 - accuracy: 0.2671 - val_loss: 2.2777 - val_accuracy: 0.1899\n","Epoch 43/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9914 - accuracy: 0.2750 - val_loss: 2.1621 - val_accuracy: 0.1985\n","Epoch 44/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0085 - accuracy: 0.2758 - val_loss: 2.1405 - val_accuracy: 0.2119\n","Epoch 45/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0099 - accuracy: 0.2752 - val_loss: 2.2552 - val_accuracy: 0.1941\n","Epoch 46/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0110 - accuracy: 0.2692 - val_loss: 2.3466 - val_accuracy: 0.1540\n","Epoch 47/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0032 - accuracy: 0.2712 - val_loss: 2.1550 - val_accuracy: 0.2284\n","Epoch 48/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0008 - accuracy: 0.2740 - val_loss: 2.1937 - val_accuracy: 0.2025\n","Epoch 49/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9944 - accuracy: 0.2784 - val_loss: 2.1905 - val_accuracy: 0.2208\n","Epoch 50/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9989 - accuracy: 0.2789 - val_loss: 2.1703 - val_accuracy: 0.1953\n","batch_size:512, l2_ratio:0.001, dropout_rate:0.2\n","Epoch 1/50\n","98/98 [==============================] - 2s 10ms/step - loss: 3.6163 - accuracy: 0.2386 - val_loss: 2.9482 - val_accuracy: 0.3202\n","Epoch 2/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.7740 - accuracy: 0.3453 - val_loss: 2.7390 - val_accuracy: 0.2629\n","Epoch 3/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.4140 - accuracy: 0.3827 - val_loss: 2.5343 - val_accuracy: 0.2605\n","Epoch 4/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.1807 - accuracy: 0.3990 - val_loss: 2.3969 - val_accuracy: 0.2874\n","Epoch 5/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0478 - accuracy: 0.4043 - val_loss: 2.1919 - val_accuracy: 0.3026\n","Epoch 6/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9357 - accuracy: 0.4230 - val_loss: 2.2802 - val_accuracy: 0.2916\n","Epoch 7/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8847 - accuracy: 0.4178 - val_loss: 2.0079 - val_accuracy: 0.3487\n","Epoch 8/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8341 - accuracy: 0.4235 - val_loss: 1.8275 - val_accuracy: 0.4127\n","Epoch 9/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8033 - accuracy: 0.4218 - val_loss: 1.8660 - val_accuracy: 0.3758\n","Epoch 10/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7528 - accuracy: 0.4302 - val_loss: 1.8249 - val_accuracy: 0.3809\n","Epoch 11/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7101 - accuracy: 0.4341 - val_loss: 1.7718 - val_accuracy: 0.4104\n","Epoch 12/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.7028 - accuracy: 0.4357 - val_loss: 1.8350 - val_accuracy: 0.3830\n","Epoch 13/50\n","98/98 [==============================] - 1s 9ms/step - loss: 1.6757 - accuracy: 0.4416 - val_loss: 1.8864 - val_accuracy: 0.3715\n","Epoch 14/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6689 - accuracy: 0.4429 - val_loss: 1.7635 - val_accuracy: 0.4117\n","Epoch 15/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6530 - accuracy: 0.4462 - val_loss: 1.6626 - val_accuracy: 0.4430\n","Epoch 16/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6308 - accuracy: 0.4520 - val_loss: 1.5825 - val_accuracy: 0.4627\n","Epoch 17/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6183 - accuracy: 0.4565 - val_loss: 1.6172 - val_accuracy: 0.4572\n","Epoch 18/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6234 - accuracy: 0.4529 - val_loss: 1.6098 - val_accuracy: 0.4572\n","Epoch 19/50\n","98/98 [==============================] - 1s 7ms/step - loss: 1.6021 - accuracy: 0.4640 - val_loss: 1.6645 - val_accuracy: 0.4367\n","Epoch 20/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6127 - accuracy: 0.4595 - val_loss: 1.6187 - val_accuracy: 0.4567\n","Epoch 21/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6095 - accuracy: 0.4570 - val_loss: 1.6821 - val_accuracy: 0.4266\n","Epoch 22/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.6125 - accuracy: 0.4563 - val_loss: 1.7651 - val_accuracy: 0.4114\n","Epoch 23/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5949 - accuracy: 0.4616 - val_loss: 1.6601 - val_accuracy: 0.4291\n","Epoch 24/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5903 - accuracy: 0.4613 - val_loss: 1.6039 - val_accuracy: 0.4550\n","Epoch 25/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5882 - accuracy: 0.4622 - val_loss: 1.6255 - val_accuracy: 0.4453\n","Epoch 26/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5856 - accuracy: 0.4678 - val_loss: 1.6265 - val_accuracy: 0.4456\n","Epoch 27/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5727 - accuracy: 0.4706 - val_loss: 1.6296 - val_accuracy: 0.4464\n","Epoch 28/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5774 - accuracy: 0.4673 - val_loss: 1.6937 - val_accuracy: 0.4209\n","Epoch 29/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5841 - accuracy: 0.4675 - val_loss: 1.7567 - val_accuracy: 0.3841\n","Epoch 30/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5525 - accuracy: 0.4779 - val_loss: 1.6278 - val_accuracy: 0.4478\n","Epoch 31/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5638 - accuracy: 0.4709 - val_loss: 1.5496 - val_accuracy: 0.4812\n","Epoch 32/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5725 - accuracy: 0.4711 - val_loss: 1.6874 - val_accuracy: 0.4201\n","Epoch 33/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5612 - accuracy: 0.4691 - val_loss: 1.6378 - val_accuracy: 0.4489\n","Epoch 34/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5583 - accuracy: 0.4721 - val_loss: 1.6256 - val_accuracy: 0.4420\n","Epoch 35/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5638 - accuracy: 0.4696 - val_loss: 1.7702 - val_accuracy: 0.3887\n","Epoch 36/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5735 - accuracy: 0.4674 - val_loss: 1.7220 - val_accuracy: 0.4235\n","Epoch 37/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5390 - accuracy: 0.4790 - val_loss: 1.5921 - val_accuracy: 0.4664\n","Epoch 38/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5397 - accuracy: 0.4797 - val_loss: 1.6345 - val_accuracy: 0.4366\n","Epoch 39/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5365 - accuracy: 0.4814 - val_loss: 1.6550 - val_accuracy: 0.4407\n","Epoch 40/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5487 - accuracy: 0.4765 - val_loss: 1.6340 - val_accuracy: 0.4486\n","Epoch 41/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5506 - accuracy: 0.4771 - val_loss: 1.6823 - val_accuracy: 0.4356\n","Epoch 42/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5592 - accuracy: 0.4767 - val_loss: 1.8228 - val_accuracy: 0.3877\n","Epoch 43/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5545 - accuracy: 0.4791 - val_loss: 1.6737 - val_accuracy: 0.4261\n","Epoch 44/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5555 - accuracy: 0.4753 - val_loss: 1.5584 - val_accuracy: 0.4722\n","Epoch 45/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5360 - accuracy: 0.4831 - val_loss: 1.6016 - val_accuracy: 0.4519\n","Epoch 46/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5385 - accuracy: 0.4839 - val_loss: 1.9436 - val_accuracy: 0.3420\n","Epoch 47/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5404 - accuracy: 0.4802 - val_loss: 1.7833 - val_accuracy: 0.3990\n","Epoch 48/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5357 - accuracy: 0.4862 - val_loss: 1.6860 - val_accuracy: 0.4145\n","Epoch 49/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5203 - accuracy: 0.4913 - val_loss: 1.7994 - val_accuracy: 0.3871\n","Epoch 50/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.5405 - accuracy: 0.4820 - val_loss: 1.6453 - val_accuracy: 0.4367\n","batch_size:512, l2_ratio:0.001, dropout_rate:0.5\n","Epoch 1/50\n","98/98 [==============================] - 2s 11ms/step - loss: 3.9354 - accuracy: 0.1531 - val_loss: 2.9458 - val_accuracy: 0.2790\n","Epoch 2/50\n","98/98 [==============================] - 1s 8ms/step - loss: 3.0018 - accuracy: 0.2390 - val_loss: 2.6396 - val_accuracy: 0.2471\n","Epoch 3/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.5848 - accuracy: 0.2826 - val_loss: 2.4826 - val_accuracy: 0.2189\n","Epoch 4/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.3728 - accuracy: 0.3001 - val_loss: 2.4852 - val_accuracy: 0.2211\n","Epoch 5/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.2150 - accuracy: 0.3209 - val_loss: 2.2758 - val_accuracy: 0.2594\n","Epoch 6/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.1438 - accuracy: 0.3228 - val_loss: 2.3915 - val_accuracy: 0.2289\n","Epoch 7/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.1029 - accuracy: 0.3199 - val_loss: 2.0433 - val_accuracy: 0.3154\n","Epoch 8/50\n","98/98 [==============================] - 1s 8ms/step - loss: 2.0450 - accuracy: 0.3310 - val_loss: 1.9153 - val_accuracy: 0.3748\n","Epoch 9/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9927 - accuracy: 0.3370 - val_loss: 1.9732 - val_accuracy: 0.3186\n","Epoch 10/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9697 - accuracy: 0.3334 - val_loss: 1.9525 - val_accuracy: 0.3452\n","Epoch 11/50\n","98/98 [==============================] - 1s 9ms/step - loss: 1.9485 - accuracy: 0.3339 - val_loss: 1.9004 - val_accuracy: 0.3529\n","Epoch 12/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9313 - accuracy: 0.3346 - val_loss: 1.8630 - val_accuracy: 0.3624\n","Epoch 13/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9265 - accuracy: 0.3364 - val_loss: 1.8221 - val_accuracy: 0.3817\n","Epoch 14/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9096 - accuracy: 0.3345 - val_loss: 1.8706 - val_accuracy: 0.3612\n","Epoch 15/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9228 - accuracy: 0.3277 - val_loss: 2.0150 - val_accuracy: 0.3109\n","Epoch 16/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9196 - accuracy: 0.3338 - val_loss: 1.8684 - val_accuracy: 0.3729\n","Epoch 17/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8952 - accuracy: 0.3410 - val_loss: 1.8676 - val_accuracy: 0.3609\n","Epoch 18/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9069 - accuracy: 0.3283 - val_loss: 1.8635 - val_accuracy: 0.3261\n","Epoch 19/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.9108 - accuracy: 0.3320 - val_loss: 1.8380 - val_accuracy: 0.3628\n","Epoch 20/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8868 - accuracy: 0.3394 - val_loss: 1.9517 - val_accuracy: 0.3114\n","Epoch 21/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8896 - accuracy: 0.3366 - val_loss: 1.8830 - val_accuracy: 0.3360\n","Epoch 22/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8836 - accuracy: 0.3374 - val_loss: 1.9044 - val_accuracy: 0.3430\n","Epoch 23/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8921 - accuracy: 0.3325 - val_loss: 1.8483 - val_accuracy: 0.3847\n","Epoch 24/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8869 - accuracy: 0.3365 - val_loss: 1.9206 - val_accuracy: 0.3487\n","Epoch 25/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8758 - accuracy: 0.3393 - val_loss: 1.8583 - val_accuracy: 0.3635\n","Epoch 26/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8697 - accuracy: 0.3439 - val_loss: 1.8602 - val_accuracy: 0.3834\n","Epoch 27/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8732 - accuracy: 0.3418 - val_loss: 1.9038 - val_accuracy: 0.3518\n","Epoch 28/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8526 - accuracy: 0.3478 - val_loss: 1.8665 - val_accuracy: 0.3562\n","Epoch 29/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8591 - accuracy: 0.3501 - val_loss: 1.9021 - val_accuracy: 0.3217\n","Epoch 30/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8616 - accuracy: 0.3442 - val_loss: 1.8868 - val_accuracy: 0.3391\n","Epoch 31/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8903 - accuracy: 0.3367 - val_loss: 1.8742 - val_accuracy: 0.3478\n","Epoch 32/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8609 - accuracy: 0.3471 - val_loss: 1.9457 - val_accuracy: 0.3092\n","Epoch 33/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8720 - accuracy: 0.3380 - val_loss: 1.9846 - val_accuracy: 0.3274\n","Epoch 34/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8779 - accuracy: 0.3395 - val_loss: 1.8957 - val_accuracy: 0.3483\n","Epoch 35/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8671 - accuracy: 0.3454 - val_loss: 1.9070 - val_accuracy: 0.3294\n","Epoch 36/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8652 - accuracy: 0.3381 - val_loss: 1.9009 - val_accuracy: 0.3559\n","Epoch 37/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8714 - accuracy: 0.3349 - val_loss: 1.9250 - val_accuracy: 0.2992\n","Epoch 38/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8762 - accuracy: 0.3393 - val_loss: 1.8711 - val_accuracy: 0.3605\n","Epoch 39/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8775 - accuracy: 0.3383 - val_loss: 1.9216 - val_accuracy: 0.3496\n","Epoch 40/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8673 - accuracy: 0.3381 - val_loss: 1.9642 - val_accuracy: 0.3312\n","Epoch 41/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8555 - accuracy: 0.3430 - val_loss: 1.8567 - val_accuracy: 0.3632\n","Epoch 42/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8588 - accuracy: 0.3377 - val_loss: 1.9262 - val_accuracy: 0.3305\n","Epoch 43/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8620 - accuracy: 0.3410 - val_loss: 1.9580 - val_accuracy: 0.3323\n","Epoch 44/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8573 - accuracy: 0.3458 - val_loss: 1.9504 - val_accuracy: 0.3244\n","Epoch 45/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8581 - accuracy: 0.3394 - val_loss: 1.8924 - val_accuracy: 0.3360\n","Epoch 46/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8574 - accuracy: 0.3442 - val_loss: 1.9200 - val_accuracy: 0.3458\n","Epoch 47/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8603 - accuracy: 0.3424 - val_loss: 1.9416 - val_accuracy: 0.3281\n","Epoch 48/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8694 - accuracy: 0.3424 - val_loss: 1.9453 - val_accuracy: 0.3222\n","Epoch 49/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8583 - accuracy: 0.3458 - val_loss: 2.0133 - val_accuracy: 0.3101\n","Epoch 50/50\n","98/98 [==============================] - 1s 8ms/step - loss: 1.8599 - accuracy: 0.3455 - val_loss: 1.9508 - val_accuracy: 0.3245\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3A7jZDgXpCQL"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\"\"\"Code Here\n","將結果繪出\n","\"\"\""],"execution_count":null,"outputs":[]}]}