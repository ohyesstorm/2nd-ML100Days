{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day097_Keras_CNN_vs_DNN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"dIuNs1pBvgI_","executionInfo":{"status":"ok","timestamp":1614953841662,"user_tz":-480,"elapsed":1939,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uz6gDrLTvgJG","executionInfo":{"status":"ok","timestamp":1614953876522,"user_tz":-480,"elapsed":6386,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"6a71cb69-2ef1-404d-9a7d-ac797af402f9"},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ERG5NUiKvgJH"},"source":["## 首先我們使用一般的 DNN (MLP) 來訓練\n","由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZ3T5EptvgJH","executionInfo":{"status":"ok","timestamp":1614954118206,"user_tz":-480,"elapsed":1319,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"890b61cc-357e-46b2-924b-519fe6b23615"},"source":["# 將資料攤平成一維資料\n","x_train = x_train.reshape(50000, 3072) \n","x_test = x_test.reshape(10000, 3072)\n","\n","# 將資料變為 float32 並標準化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UU8UdjHvgJI","executionInfo":{"status":"ok","timestamp":1614954143202,"user_tz":-480,"elapsed":24287,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"05ebd744-5ba1-4648-c592-49118ee30aa3"},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(3072,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 512)               1573376   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 5s 4ms/step - loss: 2.6435 - accuracy: 0.1987 - val_loss: 1.8935 - val_accuracy: 0.3021\n","Epoch 2/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.8778 - accuracy: 0.3190 - val_loss: 1.7625 - val_accuracy: 0.3655\n","Epoch 3/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.7930 - accuracy: 0.3555 - val_loss: 1.6988 - val_accuracy: 0.3879\n","Epoch 4/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.7368 - accuracy: 0.3768 - val_loss: 1.6788 - val_accuracy: 0.4085\n","Epoch 5/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.6888 - accuracy: 0.3956 - val_loss: 1.6972 - val_accuracy: 0.3818\n","Epoch 6/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.6724 - accuracy: 0.3986 - val_loss: 1.5840 - val_accuracy: 0.4373\n","Epoch 7/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.6351 - accuracy: 0.4149 - val_loss: 1.5948 - val_accuracy: 0.4351\n","Epoch 8/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.6272 - accuracy: 0.4186 - val_loss: 1.6359 - val_accuracy: 0.4191\n","Epoch 9/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.6163 - accuracy: 0.4211 - val_loss: 1.5478 - val_accuracy: 0.4488\n","Epoch 10/10\n","391/391 [==============================] - 1s 4ms/step - loss: 1.5928 - accuracy: 0.4255 - val_loss: 1.5707 - val_accuracy: 0.4340\n","Test loss: 1.570663571357727\n","Test accuracy: 0.4339999854564667\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S5vS5TiRvgJI"},"source":["## 接下來我們使用 CNN 來訓練神經網路\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3vffgFsvgJI","executionInfo":{"status":"ok","timestamp":1614954179692,"user_tz":-480,"elapsed":1617,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"fa13bb28-974a-48d3-a577-ee4362929ccb"},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgSUjunzvgJJ","executionInfo":{"status":"ok","timestamp":1614954272054,"user_tz":-480,"elapsed":61868,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"05c395c6-7ad2-445f-fe26-aa15bc8a9f42"},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation (Activation)      (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2304)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 32s 9ms/step - loss: 1.9596 - accuracy: 0.2845 - val_loss: 1.3652 - val_accuracy: 0.5136\n","Epoch 2/10\n","391/391 [==============================] - 3s 8ms/step - loss: 1.3325 - accuracy: 0.5284 - val_loss: 1.1197 - val_accuracy: 0.6005\n","Epoch 3/10\n","391/391 [==============================] - 3s 8ms/step - loss: 1.1069 - accuracy: 0.6113 - val_loss: 0.9544 - val_accuracy: 0.6612\n","Epoch 4/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.9541 - accuracy: 0.6682 - val_loss: 0.9134 - val_accuracy: 0.6776\n","Epoch 5/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.8610 - accuracy: 0.6966 - val_loss: 0.8109 - val_accuracy: 0.7174\n","Epoch 6/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.7928 - accuracy: 0.7231 - val_loss: 0.7790 - val_accuracy: 0.7323\n","Epoch 7/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.7559 - accuracy: 0.7383 - val_loss: 0.7376 - val_accuracy: 0.7464\n","Epoch 8/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.7057 - accuracy: 0.7545 - val_loss: 0.7469 - val_accuracy: 0.7429\n","Epoch 9/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.6691 - accuracy: 0.7681 - val_loss: 0.6701 - val_accuracy: 0.7726\n","Epoch 10/10\n","391/391 [==============================] - 3s 8ms/step - loss: 0.6385 - accuracy: 0.7815 - val_loss: 0.6684 - val_accuracy: 0.7757\n","Test loss: 0.6684233546257019\n","Test accuracy: 0.7756999731063843\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iRdGJ3wEvgJJ"},"source":["## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"beFBoKHevgJJ"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響? \\\\\n","Ans. 可以調很多個，此處先將CNN的neuron數量加多，暫且不加深，可以發現testing accuracy有提升\n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪? \\\\\n","Ans. CNN的原始目的的其中一項就是為了減少參數數量，自然是CNN的參數較少。參數數量不同的原因在於，以同個照片來說，CNN使用的是filters重複使用在每一個pixel上，而DNN則對於每個pixel都下了權重，所以餐數量差距極多。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLucC6iPvgJK","executionInfo":{"status":"ok","timestamp":1614954508116,"user_tz":-480,"elapsed":78114,"user":{"displayName":"葉秋","photoUrl":"","userId":"10703600004193647245"}},"outputId":"b3d50c56-74fd-4812-bb88-c32c73d48b48"},"source":["model = Sequential()\n","model.add(Conv2D(128, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(128, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 32, 32, 128)       3584      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 30, 30, 128)       147584    \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 30, 30, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 15, 15, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 15, 15, 128)       147584    \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 15, 15, 128)       0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 13, 13, 128)       147584    \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 13, 13, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 512)               2359808   \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 2,811,274\n","Trainable params: 2,811,274\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","391/391 [==============================] - 9s 21ms/step - loss: 2.2232 - accuracy: 0.2329 - val_loss: 1.8401 - val_accuracy: 0.3345\n","Epoch 2/10\n","391/391 [==============================] - 7s 19ms/step - loss: 1.3484 - accuracy: 0.5246 - val_loss: 0.9499 - val_accuracy: 0.6693\n","Epoch 3/10\n","391/391 [==============================] - 7s 19ms/step - loss: 1.0290 - accuracy: 0.6442 - val_loss: 0.9618 - val_accuracy: 0.6612\n","Epoch 4/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.8625 - accuracy: 0.7060 - val_loss: 0.8759 - val_accuracy: 0.7046\n","Epoch 5/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.7490 - accuracy: 0.7393 - val_loss: 0.7469 - val_accuracy: 0.7416\n","Epoch 6/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.6875 - accuracy: 0.7612 - val_loss: 0.7486 - val_accuracy: 0.7501\n","Epoch 7/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.6286 - accuracy: 0.7849 - val_loss: 0.6727 - val_accuracy: 0.7812\n","Epoch 8/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.5984 - accuracy: 0.7965 - val_loss: 0.6520 - val_accuracy: 0.7908\n","Epoch 9/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.5877 - accuracy: 0.8008 - val_loss: 0.6652 - val_accuracy: 0.7894\n","Epoch 10/10\n","391/391 [==============================] - 7s 19ms/step - loss: 0.5673 - accuracy: 0.8109 - val_loss: 0.7449 - val_accuracy: 0.7930\n","Test loss: 0.7449085712432861\n","Test accuracy: 0.7929999828338623\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7KbNaGs5yP4B"},"source":[""],"execution_count":null,"outputs":[]}]}